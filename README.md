# IA : D√©tection d'objet sur image

## üìå Sommaire:

I. [Badges](#üéØ-badges)

II. [Introduction](#üåü-introduction)

III. [Explications](#üìñ-explications)

IV. [Cas concret](#üíª-cas-concret)


## üéØ Badges

[![Python logo](https://img.shields.io/badge/Language-Python-green
)](https://www.php.net/)
[![Yolo logo](https://img.shields.io/badge/NCC-Yolo-blue
)](https://www.ultralytics.com/fr/yolo)
[![Roboflow logo](https://img.shields.io/badge/Dataset-Roboflow-purple
)](https://universe.roboflow.com)

## üåü Introduction

La d√©tection d'objets est une t√¢che de vision par ordinateur qui consiste √† identifier et localiser des objets dans des images ou des vid√©os. Il s‚Äôagit d‚Äôun √©l√©ment important de nombreuses applications, telles que les voitures autonomes, la robotique et la vid√©osurveillance.

Il existe plusieurs types de vision par ordinateur : 

- La ***classification*** d'images d√©terminent la classe d'un objet sur l'image et renvoient son nom ainsi que la probabilit√© de cette pr√©diction.

- La ***d√©tection*** d'objets, en plus du type et de la probabilit√© de l'objet, renvoient aussi les coordonn√©es de l'objet sur l'image : x, y, largeur et hauteur. Ces r√©seaux peuvent d√©tecter plusieurs objets dans une image et leurs bo√Ætes englobantes.

- La ***segmentation*** d'images d√©tectent non seulement le type d'objets et leurs bo√Ætes englobantes, mais aussi les formes pr√©cises des objets sur l'image.

![Type](./src/compvision_tasks.png)
---

Au fil des ann√©es, de nombreuses m√©thodes et algorithmes ont √©t√© d√©velopp√©s pour rechercher des objets dans les images et leurs positions. La meilleure qualit√© dans l‚Äôex√©cution de ces t√¢ches provient de l‚Äôutilisation de r√©seaux de neurones convolutifs (CNN).

## üìñ Explications :

### Mais qu'est-ce qu'un r√©seau de neurones convolutifs (CNN) ?

Pour faire simple, les CNN sont des mod√®les puissants pour reconna√Ætre et classer des images. Ils utilisent des op√©rations de convolution pour d√©tecter automatiquement les caract√©ristiques importantes des images. Cela r√©duit la complexit√© des calculs tout en offrant de bonnes performances.

### Exemple d'Op√©ration de Convolution

Pour mieux comprendre, voici un petit exemple :

1. **Image d'origine (5x5 pixels) :**
    ```
    1 1 1 0 0
    0 1 1 1 0
    0 0 1 1 1
    0 0 1 1 0
    0 1 1 0 0
    ```

2. **Filtre (ou noyau) (3x3 pixels) :**
    ```
    1 0 1
    0 1 0
    1 0 1
    ```

3. **Convolution :**
    - Le filtre se d√©place sur l'image, pixel par pixel.
    - √Ä chaque position, il multiplie les valeurs de l'image par les valeurs du filtre et additionne les r√©sultats.

4. **Calcul de Convolution √† une position :**
    - Position du filtre : en haut √† gauche de l'image.
    - Multiplications et somme :
        ```
        1*1 + 1*0 + 1*1
        0*0 + 1*1 + 1*0
        0*1 + 0*0 + 1*1
        = 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1
        = 4
        ```

5. **Carte de Caract√©ristiques (r√©sultat de la convolution) :**
    ```
    4 3 3 ...
    1 4 4 ...
    1 2 4 ...
    ...
    ```

### Qu'est-ce que le Pooling ?

Le pooling est une op√©ration importante dans les CNN qui r√©duit la taille des cartes de caract√©ristiques tout en conservant les informations importantes. Cela aide √† diminuer la complexit√© computationnelle et √† rendre le mod√®le plus robuste aux variations et aux translations dans les images. Le pooling le plus couramment utilis√© est le max-pooling, qui prend le maximum d'une petite r√©gion de la carte de caract√©ristiques.

### Pourquoi les CNN sont-ils efficaces ?

- **Exploitation des relations spatiales :** Les CNN capturent les relations locales dans les images, comme les bords et les textures.
- **Partage des Poids :** Les m√™mes filtres sont utilis√©s partout dans l'image, r√©duisant le nombre de param√®tres √† apprendre.
- **Invariance aux translations :** Les op√©rations de pooling aident √† rendre les caract√©ristiques extraites invariantes aux petites translations dans l'image.

En r√©sum√©, les CNN apprennent automatiquement √† d√©tecter les caract√©ristiques importantes des images gr√¢ce √† des op√©rations de convolution et de pooling, rendant la reconnaissance et la classification des images plus efficaces et pr√©cises.


## Entra√Ænement d'un Mod√®le de D√©tection d'Objets

L'entra√Ænement du mod√®le de d√©tection d'objets est essentiel afin de rendre celui-ci performant. Pour se faire, on utilise des **datasets**.
<br>Ils se composent essentiellement :

- Des images o√π chaque objet est isol√©, sans l'arri√®re-plan.
- Des annotations indiquant la classe de chaque objet et sa position dans l'image √† l'aide de bo√Ætes englobantes.
- Des divisions en ensembles d'entra√Ænement, de validation et de test.

*De nombreux dataset sont disponibles en [ligne](https://universe.roboflow.com) mais il est √©galement possible de cr√©er son propre dataset √† l'aide de diff√©rents outil comme celui de [roboflow](https://app.roboflow.com)* 

### Phase d'Entra√Ænement

La phase d'entra√Ænement se d√©roule en cycles comprenant deux phases principales : la phase d'entra√Ænement et la phase de validation.
Le processus suit ces √©tapes :

1. **Extraction d'un Batch Al√©atoire :**
   - Un lot (batch) al√©atoire d'images est extrait du dataset d'entra√Ænement. La taille de ce lot peut √™tre sp√©cifi√©e √† l'aide d'une option de lot (batch).

2. **Propagation dans le Mod√®le :**
   - Les images du batch sont pass√©es √† travers le mod√®le CNN. Le mod√®le pr√©dit les bo√Ætes englobantes des objets d√©tect√©s et leurs classes associ√©es.

3. **Calcul de la Fonction de Perte :**
   - Les pr√©dictions du mod√®le sont compar√©es aux annotations correctes (v√©rit√© terrain) des images, disponibles dans les fichiers d'annotations.
   - Une fonction de perte est utilis√©e pour mesurer l'√©cart entre les pr√©dictions du mod√®le et les v√©rit√©s terrains. Cela quantifie l'erreur du mod√®le.

4. **Optimisation des Poids :**
   - Le r√©sultat de la fonction de perte est utilis√© par l'optimiseur (par exemple, SGD ou Adam) pour ajuster les poids du mod√®le. L'objectif est de r√©duire l'erreur pour les cycles d'entra√Ænement suivants.

### Phase de Validation

Pendant la phase de validation, le processus est le suivant :

1. **Extraction des Images de Validation :**
   - Les images du dataset de validation sont extraites.

2. **√âvaluation du Mod√®le :**
   - Les images de validation sont pass√©es √† travers le mod√®le pour pr√©dire les bo√Ætes englobantes des objets d√©tect√©s.

3. **√âvaluation de la Pr√©cision :**
   - Les pr√©dictions du mod√®le sont compar√©es aux annotations correctes des images de validation.
   - La pr√©cision du mod√®le est calcul√©e en mesurant la concordance entre les pr√©dictions et les annotations.

### Visualisation et Suivi

√Ä chaque epoch (it√©ration sur l'ensemble des donn√©es d'entra√Ænement), les progr√®s et les r√©sultats de chaque phase (entra√Ænement et validation) sont affich√©s √† l'√©cran. Cela permet de suivre comment le mod√®le apprend et s'am√©liore au fil du temps.

## üíª Cas concret :

Le r√©seau de neurones le plus populaire pour de la d√©tection d'image est [Yolo](https://www.ultralytics.com/fr/yolo) de la soci√©t√© ultralytics. Il est capable de de r√©soudre des probl√®mes de classification, d√©tection et de segmentation.

Dans ce repo, se trouve l'ensemble des programmes permettant d'utiliser et entra√Æner un mod√®le d'apprentissage capable de faire de la **d√©tection d'objets**.

- Les [mod√®les](./mod√®les/) disponibles :

    - [yolov8m](./mod√®les/yolov8m.pt) : pr√©-entra√Æn√© avec [COCO](https://cocodataset.org/#home) mis √† disposition par l'API de YOLOv8
    - [climbing_shoes](./mod√®les/climbing_shoes.pt) : entra√Æn√© avec le dataset [climbin_shoes.pt](./dataset/Climbing-shoes.v2i.yolov8/)

- Les [programmes](./prg/) disponibles :

    - [recognize_initial](./prg/recognize_initial.ipynb) : pour tester une image avec un mod√®le
    - [recognize_train](./prg/recognize_train.ipynb) : pour entra√Æner son propre mod√®le

- Des [images](./img/) de tests

- Des [datasets](./dataset/)

- Un [site web](./website/) d√©velopp√© avec Flask pour tester une image directement via le site

## üîß Instruction d'installation

1. Cloner le repository

```bash
git clone 
```
2. Aller dans le repository 

```bash
cd projet_data
```
3. Cr√©er un environnement virtuel

```bash
python3 -m venv venv
```
4. Activer l'environment virtuel<br>

```bash
#Sur Windows:
venv\Scripts\activate

#Sur macOS and Linux:
source venv/bin/activate
```

5. Installer les paquets requis

```bash
pip install -r requirements.txt
```

## üíª Manipuler les mod√®les

#### 1. Aller dans le dossier 'prg'

#### 2. Editez directement le/les fichiers souhait√©(s)


## üíª D√©marrer le site

#### 1. Aller dans le dossier 'website'

```bash
cd website
```
#### 2. Lancer le server

```bash
python .\object_detector.py
```

#### 3. Acc√©der au site

Visiter http://localhost:8080 dans votre navigateur internet